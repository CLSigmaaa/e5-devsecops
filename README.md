# Maquette Kubernetes - D√©ploiement de 3 Applications (Django incluse)

Ce d√©p√¥t pr√©sente une maquette fonctionnelle de migration vers Kubernetes pour un client ayant 3 applications √† exposer sur les ports 80, 8080 et 9090. L'une d'elles est critique, d√©velopp√©e avec Django.

## üéØ Objectifs

- Containeriser les 3 applications avec Docker, en **optimisant les images**.
- D√©ployer 3 applications dans **Kubernetes** avec :
  - Un **Deployment**
  - Un **Service**
  - **Au moins un Ingress**
- S√©parer **chaque composant** dans un manifeste distinct.
- Permettre un **acc√®s externe** aux applications.

## Qu'est-ce que Kubernetes ?

Kubernetes est un syst√®me open-source de gestion de conteneurs qui automatise le d√©ploiement, la mise √† l'√©chelle et la gestion des applications conteneuris√©es. Il permet de g√©rer des clusters de machines virtuelles ou physiques, en orchestrant le d√©ploiement et la mise √† l'√©chelle des applications dans des environnements distribu√©s.

## Qu'est-ce que Minikube ?

Minikube est un outil qui facilite l'ex√©cution de Kubernetes localement. Il cr√©e un cluster Kubernetes √† une seule machine virtuelle sur votre ordinateur, ce qui permet de tester et de d√©velopper des applications conteneuris√©es sans avoir besoin d'un environnement de production complet.

## Qu'est-ce que Docker ?

Docker est une plateforme de conteneurisation qui permet de cr√©er, d√©ployer et ex√©cuter des applications dans des conteneurs. Un conteneur est une unit√© standardis√©e de logiciel qui regroupe le code de l'application et toutes ses d√©pendances, garantissant ainsi que l'application fonctionne de mani√®re coh√©rente sur diff√©rents environnements.

## Structure du d√©p√¥t

```
k8s-maquette/
‚îÇ
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ app1/ (port 80)
‚îÇ   ‚îú‚îÄ‚îÄ app2/ (port 8080)
‚îÇ   ‚îî‚îÄ‚îÄ app3/ (port 9000)
‚îÇ
‚îú‚îÄ‚îÄ k8s/
‚îÇ   ‚îú‚îÄ‚îÄ app1-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app1-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app2-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app2-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app3-deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app3-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ app3-ingress.yaml
```
## Les objets Kubernetes

- **Pod** : Unit√© de base de Kubernetes, repr√©sentant un ou plusieurs conteneurs qui partagent le m√™me r√©seau et le m√™me stockage.

- **Deployment** : G√®re la cr√©ation et la mise √† jour des Pods, garantissant que le nombre sp√©cifi√© de Pods est en cours d'ex√©cution √† tout moment.

- **Service** : Permet de d√©finir une politique d'acc√®s aux Pods, en exposant une interface r√©seau stable pour acc√©der √† un ensemble de Pods.

- **Ingress** : G√®re l'acc√®s externe aux services dans un cluster, en fournissant des r√®gles de routage HTTP et HTTPS.

- **IngressController** : Composant qui g√®re les Ingress, en configurant un √©quilibreur de charge pour diriger le trafic vers les services appropri√©s.

- **ReplicaSet** : Assure qu'un nombre sp√©cifi√© de r√©pliques d'un Pod est en cours d'ex√©cution √† tout moment.

- **ConfigMap** : Permet de stocker des donn√©es de configuration sous forme de paires cl√©-valeur, qui peuvent √™tre utilis√©es par les Pods.

- **Secret** : Similaire √† ConfigMap, mais con√ßu pour stocker des donn√©es sensibles, comme des mots de passe ou des cl√©s d'API.


## Service

Permet de d√©finir une politique d'acc√®s aux Pods, en exposant une interface r√©seau stable pour acc√©der √† un ensemble de Pods.

### Les types de Service Kubernetes

Kubernetes propose plusieurs types de services pour exposer les applications d√©ploy√©es dans un cluster. Voici les trois principaux types de services utilis√©s dans ce projet :

#### 1. **ClusterIP**
- **Description** : C'est le type de service par d√©faut. Il expose le service √† l'int√©rieur du cluster Kubernetes, permettant aux autres pods du cluster d'y acc√©der.
- **Cas d'utilisation** : Id√©al pour les communications internes entre les applications ou les microservices dans le cluster.
- **Exemple** : Si une application front-end doit communiquer avec une API back-end dans le m√™me cluster, un service de type ClusterIP peut √™tre utilis√©.

#### 2. **NodePort**
- **Description** : Ce type de service expose une application sur un port sp√©cifique de chaque n≈ìud du cluster. Cela permet d'acc√©der √† l'application depuis l'ext√©rieur du cluster en utilisant l'adresse IP du n≈ìud et le port expos√©.
- **Cas d'utilisation** : Utile pour des tests ou des environnements de d√©veloppement o√π un acc√®s direct √† l'application est n√©cessaire.
- **Exemple dans ce projet** : App1 (Django) est expos√©e via un service NodePort sur le port `30001`.

#### 3. **LoadBalancer**
- **Description** : Ce type de service cr√©e automatiquement un √©quilibreur de charge externe (si pris en charge par le fournisseur de cloud) pour distribuer le trafic vers les pods associ√©s. Il attribue √©galement une adresse IP externe pour acc√©der au service.
- **Cas d'utilisation** : Id√©al pour les environnements de production o√π un acc√®s externe fiable et √©quilibr√© est requis.
- **Exemple dans ce projet** : App2 (Flask) et App3 (Django) sont expos√©es via des services LoadBalancer.

### Comparaison des types de services

| Type de Service | Port Expos√© | Acc√®s Externe | Cas d'Utilisation             |
|------------------|-------------|---------------|--------------------------------|
| **ClusterIP**    | Non         | Non           | Communication interne         |
| **NodePort**     | Oui         | Oui           | Acc√®s direct pour tests ou d√©veloppement |
| **LoadBalancer** | Oui         | Oui           | Acc√®s externe en production   |

Ces services permettent de r√©pondre √† diff√©rents besoins en fonction des sc√©narios d'utilisation et des environnements.

## Installation et configuration de Minikube

### 1. Installer Kubernetes

#### Pr√©requis

Avant de commencer l'installation, assurez-vous d'avoir:

- 2 CPU ou plus
- 2GB de m√©moire libre
- 20GB d'espace disque libre
- Une connexion Internet
- Un gestionnaire de conteneurs ou de machines virtuelles comme Docker, QEMU, Hyperkit, Hyper-V, KVM, Parallels, Podman, VirtualBox, ou VMware Fusion/Workstation

#### Installation de Minikube

Pour installer la derni√®re version stable de Minikube sur Linux x86-64 avec une installation binaire:

```bash
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

### 2. Cr√©er le cluster avec Docker

V√©rifiez les versions de Kubernetes compatibles avec Minikube en affichant les param√®tres par d√©faut de la configuration Minikube. Cela permet de s'assurer que la version de Kubernetes utilis√©e est support√©e par votre installation actuelle de Minikube :

```bash
minikube config defaults kubernetes-version
```

Cette commande retourne la version par d√©faut de Kubernetes que Minikube utilise, ainsi que les versions compatibles. Si vous souhaitez utiliser une version sp√©cifique, vous pouvez la d√©finir lors de la cr√©ation du cluster avec l'option `--kubernetes-version`.

### 2.1. Cr√©er votre cluster Minikube avec Docker

Pour d√©marrer un cluster Minikube en utilisant Docker comme backend, ex√©cutez la commande suivante :

```bash
minikube start --listen-address=0.0.0.0 --memory=max --cpus=max --kubernetes-version=v1.32.0
```

#### D√©tails des options utilis√©es :
- `--listen-address=0.0.0.0` : Permet √† Minikube d'√©couter sur toutes les interfaces r√©seau, ce qui est utile pour acc√©der au cluster depuis d'autres machines sur le r√©seau.
- `--memory=max` : Alloue la quantit√© maximale de m√©moire disponible √† Minikube, garantissant ainsi des performances optimales pour le cluster.
- `--cpus=max` : Alloue tous les c≈ìurs CPU disponibles √† Minikube, ce qui est particuli√®rement utile pour les charges de travail intensives.
- `--kubernetes-version=v1.32.0` : Sp√©cifie la version de Kubernetes √† utiliser pour le cluster. Assurez-vous que cette version est compatible avec vos applications et configurations.

#### Exemple de sortie attendue :
Apr√®s avoir ex√©cut√© cette commande, vous devriez voir une sortie similaire √† celle-ci :

```bash
üòÑ  minikube v1.30.0 on Linux
‚ú®  Using the docker driver based on user configuration
üëç  Starting control plane node minikube in cluster minikube
üî•  Creating docker container (CPUs=max, Memory=max) ...
üê≥  Preparing Kubernetes v1.32.0 on Docker 20.10.17 ...
üîé  Verifying Kubernetes components...
üåü  Enabled addons: default-storageclass, storage-provisioner
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

#### V√©rification du cluster :
Une fois le cluster d√©marr√©, vous pouvez v√©rifier son √©tat avec les commandes suivantes :

```bash
minikube status
```

Cette commande affiche l'√©tat actuel de votre cluster Minikube, y compris les informations sur le n≈ìud, le gestionnaire de conteneurs utilis√©, et si les composants Kubernetes essentiels (comme le serveur API) sont en cours d'ex√©cution. Exemple de sortie :

```bash
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

```bash
kubectl cluster-info
```

Cette commande fournit des informations d√©taill√©es sur le cluster Kubernetes, notamment l'URL du serveur API et l'√©tat des composants principaux. Exemple de sortie :

```bash
Kubernetes control plane is running at https://127.0.0.1:6443
CoreDNS is running at https://127.0.0.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

Ces commandes permettent de s'assurer que le cluster est correctement configur√© et op√©rationnel avant de d√©ployer vos applications.

Ces commandes confirment que le cluster est op√©rationnel et pr√™t √† √™tre utilis√©.

V√©rifiez l'IP du cluster Minikube:

```bash
minikube ip
```

Cette commande retourne l'adresse IP attribu√©e au cluster Minikube. Cette IP est essentielle pour acc√©der aux services expos√©s par le cluster, notamment ceux configur√©s avec des types de service comme `NodePort` ou `LoadBalancer`. Par exemple, si vous avez un service expos√© sur un port sp√©cifique (comme 30001 pour app1), vous pouvez acc√©der √† l'application via l'URL suivante :

```
http://<minikube-ip>:<port>
```

Exemple d'utilisation :

```bash
$ minikube ip
192.168.49.2
```

Dans cet exemple, si app1 est expos√©e sur le port 30001, vous pouvez y acc√©der via :

```
http://192.168.49.2:30001
```

Assurez-vous que Minikube est en cours d'ex√©cution avant d'ex√©cuter cette commande, sinon elle ne retournera aucune IP valide.

Pour supprimer un cluster Minikube, utilisez la commande suivante :

```bash
minikube delete --purge
```

#### D√©tails des options :
- `delete` : Cette commande supprime le cluster Minikube en arr√™tant tous les composants Kubernetes associ√©s et en supprimant les ressources allou√©es.
- `--purge` : Cette option garantit que toutes les donn√©es et configurations associ√©es au cluster sont compl√®tement supprim√©es, y compris les fichiers de configuration locaux et les volumes persistants.

#### Exemple de sortie attendue :
Apr√®s avoir ex√©cut√© cette commande, vous devriez voir une sortie similaire √† celle-ci :

```bash
üî•  Deleting "minikube" in docker ...
üî•  Removing /home/user/.minikube/machines/minikube ...
üî•  Removing /home/user/.minikube/profiles/minikube ...
üî•  Removing /home/user/.kube/config ...
üî•  Removing volumes ...
üíÄ  Removed all traces of the "minikube" cluster.
```

#### Remarque :
- Cette commande est irr√©versible. Assurez-vous d'avoir sauvegard√© toutes les donn√©es importantes avant de l'ex√©cuter.
- Si vous utilisez plusieurs clusters Minikube, vous pouvez sp√©cifier le nom du cluster √† supprimer en ajoutant l'option `-p <nom_du_cluster>`.

Exemple pour un cluster nomm√© `test-cluster` :
```bash
minikube delete -p test-cluster --purge
```

Cette commande est utile pour nettoyer compl√®tement votre environnement Kubernetes local et lib√©rer de l'espace disque.

### 3. Activer l'autocompl√©tion

Documentation sur l'autocompl√©tion Minikube: [https://minikube.sigs.k8s.io/docs/commands/completion/](https://minikube.sigs.k8s.io/docs/commands/completion/)

Documentation compl√®te sur l'autocompl√©tion: [https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#enable-shell-autocompletion](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#enable-shell-autocompletion)

Ajoutez ce code dans votre fichier `.bashrc` pour activer l'autocompl√©tion:

```bash
if command -v minikube &>/dev/null
then
  eval "$(minikube completion bash)"
fi
source /etc/bash_completion
source <(minikube completion bash)
alias kubectl="minikube kubectl --"
alias k="minikube kubectl --"
alias k="kubectl"
complete -F __start_kubectl k
source <(kubectl completion bash)

# Au lieu de faire un kubectl, on peut directement utiliser la lettre k
k get all --all-namespaces
```

## √âtapes de r√©alisation

### 1. Applications
- App1 : Application Django sur le port 80
- App2 : Application Flask sur le port 8080
- App3 : Application Django sur le port 9090

Pour chaque application, il y aura un Dockerfile optimis√©.

### 2. Cr√©ation des images Docker
- Cloner les d√©p√¥ts des applications dans le r√©pertoire `apps/`.

```bash
git clone https://mon-repository.git apps/app1
```
### Cr√©ation d'un fichier `.dockerignore` pour chaque application

Le fichier `.dockerignore` est essentiel pour optimiser la construction des images Docker. Il permet d'exclure les fichiers et dossiers inutiles, r√©duisant ainsi la taille de l'image et acc√©l√©rant le processus de construction. Voici un exemple d√©taill√© de `.dockerignore` adapt√© pour chaque application.

#### Exemple de `.dockerignore` pour une application Django (App1 et App3)

```dockerignore
# Exclure les fichiers Python inutiles
*.pyc
*.pyo
*.pyd
__pycache__/

# Exclure les fichiers de configuration locaux
*.env
.env.*
*.log

# Exclure les dossiers sp√©cifiques
.git/
.vscode/
.idea/
node_modules/
dist/
build/

# Exclure les fichiers temporaires
*.swp
*.bak
*.tmp
.DS_Store
Thumbs.db

# Exclure les fichiers statiques g√©n√©r√©s
staticfiles/
media/
```

#### Explications :
- **Fichiers Python inutiles** : Les fichiers `.pyc`, `.pyo`, et le dossier `__pycache__` sont des fichiers g√©n√©r√©s automatiquement par Python et ne sont pas n√©cessaires dans l'image Docker.
- **Fichiers de configuration locaux** : Les fichiers `.env` contiennent des informations sensibles comme les cl√©s API ou les mots de passe. Ils doivent √™tre exclus pour des raisons de s√©curit√©.
- **Dossiers sp√©cifiques** : Les dossiers comme `.git/`, `.vscode/`, et `node_modules/` ne sont pas n√©cessaires pour ex√©cuter l'application dans un conteneur.
- **Fichiers temporaires** : Les fichiers comme `.swp`, `.bak`, et `.tmp` sont des fichiers temporaires g√©n√©r√©s par les √©diteurs de texte ou le syst√®me d'exploitation.
- **Fichiers statiques g√©n√©r√©s** : Les dossiers `staticfiles/` et `media/` contiennent des fichiers g√©n√©r√©s par Django et ne doivent pas √™tre inclus dans l'image Docker. Ces fichiers seront g√©n√©r√©s √† nouveau lors de l'ex√©cution du conteneur.

#### Exemple de `.dockerignore` pour une application Flask (App2)

```dockerignore
# Exclure les fichiers Python inutiles
*.pyc
*.pyo
*.pyd
__pycache__/

# Exclure les fichiers de configuration locaux
*.env
.env.*
*.log

# Exclure les dossiers sp√©cifiques
.git/
.vscode/
.idea/
node_modules/
dist/
build/

# Exclure les fichiers temporaires
*.swp
*.bak
*.tmp
.DS_Store
Thumbs.db

# Exclure les fichiers g√©n√©r√©s par Flask
instance/
```

#### Explications :
- **Fichiers g√©n√©r√©s par Flask** : Le dossier `instance/` est utilis√© par Flask pour stocker des fichiers sp√©cifiques √† l'environnement, comme les bases de donn√©es SQLite. Ces fichiers ne doivent pas √™tre inclus dans l'image Docker.

### √âtapes pour ajouter un `.dockerignore` √† chaque application

1. **Cr√©er le fichier `.dockerignore`** :
    - Dans le r√©pertoire de chaque application (`apps/app1`, `apps/app2`, `apps/app3`), cr√©ez un fichier nomm√© `.dockerignore`.

2. **Ajouter les r√®gles d'exclusion** :
    - Copiez et collez les r√®gles d'exclusion sp√©cifiques √† chaque application dans le fichier `.dockerignore`.

3. **V√©rifier l'efficacit√©** :
    - Construisez l'image Docker et v√©rifiez que les fichiers exclus ne sont pas pr√©sents dans l'image finale. Utilisez la commande suivante pour inspecter l'image :
      ```bash
      docker build -t app1:latest .
      docker run --rm -it app1:latest sh
      ```

4. **Tester les performances** :
    - Comparez la taille de l'image Docker avant et apr√®s l'ajout du fichier `.dockerignore` pour mesurer l'impact.

En suivant ces √©tapes, vous garantissez des images Docker optimis√©es, s√©curis√©es et adapt√©es √† vos besoins.

### Construction et publication des images Docker pour chaque application

#### √âtape 1 : Construction des images Docker

Pour chaque application, vous devez construire une image Docker √† partir du fichier `Dockerfile` pr√©sent dans le r√©pertoire correspondant. Voici les commandes √† ex√©cuter :

```bash
cd apps/app1
docker build -t app1:latest .
cd ../app2
docker build -t app2:latest .
cd ../app3
docker build -t app3:latest .
```

#### √âtape 2 : V√©rification des images Docker cr√©√©es

Une fois les images construites, vous pouvez v√©rifier qu'elles ont bien √©t√© cr√©√©es en listant les images Docker disponibles sur votre machine :

```bash
docker images
```

La sortie de cette commande devrait inclure les images `app1:latest`, `app2:latest`, et `app3:latest`.

#### √âtape 3 : Taguer les images pour le registre Docker

Avant de pousser les images vers un registre Docker (par exemple Docker Hub ou un registre priv√©), vous devez les taguer avec le nom du registre. Par d√©faut, les images sont tagu√©es avec le nom de l'h√¥te local.

Exemple de commande pour taguer les images :

```bash
docker tag app1:latest <docker-registry>/app1:latest
docker tag app2:latest <docker-registry>/app2:latest
docker tag app3:latest <docker-registry>/app3:latest
```

Remplacez `<docker-registry>` par l'URL ou le nom de votre registre Docker (par exemple, `docker.io/username` pour Docker Hub).

#### √âtape 4 : Connexion au registre Docker

Avant de pousser les images, connectez-vous √† votre registre Docker en utilisant la commande suivante :

```bash
docker login <docker-registry>
```

Vous serez invit√© √† entrer vos identifiants (nom d'utilisateur et mot de passe) pour le registre Docker.

#### √âtape 5 : Pousser les images vers le registre Docker

Une fois connect√©, vous pouvez pousser les images tagu√©es vers le registre Docker. Utilisez les commandes suivantes :

```bash
docker push <docker-registry>/app1:latest
docker push <docker-registry>/app2:latest
docker push <docker-registry>/app3:latest
```

#### √âtape 6 : V√©rification des images dans le registre

Apr√®s avoir pouss√© les images, connectez-vous √† l'interface web de votre registre Docker (par exemple, Docker Hub) pour v√©rifier que les images `app1:latest`, `app2:latest`, et `app3:latest` sont bien pr√©sentes.

#### R√©sum√© des commandes

Voici un r√©sum√© des commandes √† ex√©cuter pour construire, taguer, et pousser les images Docker :

```bash
# Construction des images
cd apps/app1 && docker build -t app1:latest . && cd ../app2 && docker build -t app2:latest . && cd ../app3 && docker build -t app3:latest .

# Taguer les images
docker tag app1:latest <docker-registry>/app1:latest
docker tag app2:latest <docker-registry>/app2:latest
docker tag app3:latest <docker-registry>/app3:latest

# Connexion au registre Docker
docker login <docker-registry>

# Pousser les images
docker push <docker-registry>/app1:latest
docker push <docker-registry>/app2:latest
docker push <docker-registry>/app3:latest
```

En suivant ces √©tapes, vos images Docker seront disponibles dans le registre et pr√™tes √† √™tre utilis√©es pour le d√©ploiement dans Kubernetes.

### 3. D√©ploiement dans Kubernetes
Pour chaque application, il y a un manifeste de d√©ploiement et un manifeste de service.

Le manifeste de d√©ploiement sert √† d√©ployer l'application dans Kubernetes, tandis que le manifeste de service permet d'exposer l'application √† l'ext√©rieur du cluster.

#### 3.1. D√©ploiement de l'application Django (app1)

Deployment pour app1 (app1-deployment.yaml):
Ce manifeste cr√©e un d√©ploiement pour l'application Django (app1) avec une r√©plique et expose le port 80.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app1
  template:
    metadata:
      labels:
        app: app1
    spec:
      containers:
      - name: app1
        image: clsigmaaa/app1:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 80
```
Service pour app1 (app1-service.yaml):
Ce manifeste cr√©e un service de type NodePort pour exposer l'application Django (app1) sur le port 80.

Un NodePort a √©t√© utilis√© car l'application n'est pas critique et peut √™tre expos√©e sur un port sp√©cifique de chaque n≈ìud du cluster. Cela permet d'acc√©der √† l'application depuis l'ext√©rieur du cluster en utilisant l'adresse IP du n≈ìud et le port expos√©. De plus, cela facilite le test et le d√©veloppement local.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: app1
spec:
  selector:
    app: app1
  type: NodePort
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30001
```

#### 3.2. D√©ploiement de l'application Flask (app2)
Deployment pour app2 (app2-deployment.yaml):
Ce manifeste cr√©e un d√©ploiement pour l'application Flask (app2) avec une r√©plique et expose le port 8080.
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app2
  template:
    metadata:
      labels:
        app: app2
    spec:
      containers:
      - name: app1
        image: clsigmaaa/app2:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8080

```
Service pour app2 (app2-service.yaml):
Ce manifeste cr√©e un service de type LoadBalancer pour exposer l'application Flask (app2) sur le port 8080.
```yaml
apiVersion: v1
kind: Service
metadata:
  name: app2
spec:
  selector:
    app: app2
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
```

#### 3.3. D√©ploiement de l'application Django (app3)
Deployment pour app3 (app3-deployment.yaml):
Ce manifeste cr√©e un d√©ploiement pour l'application Django (app3) avec une r√©plique et expose le port 9000.
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app3
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app3
  template:
    metadata:
      labels:
        app: app3
    spec:
      containers:
      - name: app3
        image: clsigmaaa/app3:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 9000
```
Service pour app3 (app3-service.yaml):
Ce manifeste cr√©e un service de type LoadBalancer pour exposer l'application Django (app3) sur le port 9000.

### Justification de l'utilisation d'un LoadBalancer pour App3 (Django)

Cette application √©tant l'application Django critique, il est important de justifier l'utilisation d'un LoadBalancer pour son d√©ploiement.

L'utilisation d'un **LoadBalancer** pour l'application App3 (Django) est justifi√©e par les raisons suivantes :

1. **Acc√®s externe simplifi√©**  
  Le type de service LoadBalancer permet d'exposer directement l'application √† l'ext√©rieur du cluster Kubernetes avec une adresse IP publique ou priv√©e (selon l'environnement). Cela facilite l'acc√®s √† l'application sans n√©cessiter de configuration suppl√©mentaire, comme un NodePort ou un Ingress.

2. **Distribution du trafic**  
  Si App3 est une application critique (comme mentionn√© dans le projet), un LoadBalancer peut r√©partir le trafic entre plusieurs pods r√©pliqu√©s, garantissant une meilleure disponibilit√© et une tol√©rance aux pannes.

3. **Scalabilit√©**  
  Avec un LoadBalancer, l'application peut facilement √©voluer horizontalement (ajout de r√©pliques de pods). Le trafic est automatiquement √©quilibr√© entre les nouvelles instances, assurant une gestion efficace des charges √©lev√©es.

4. **Environnement de production**  
  Le type LoadBalancer est souvent utilis√© dans des environnements de production pour fournir un point d'entr√©e stable et fiable. Cela est particuli√®rement utile pour App3, qui est une application critique.

5. **Simplicit√© de configuration**  
  Contrairement √† un NodePort, qui n√©cessite de conna√Ætre l'adresse IP du n≈ìud et le port expos√©, un LoadBalancer attribue une adresse IP unique et g√®re automatiquement le routage du trafic vers les pods.

6. **Support des fournisseurs cloud**  
  Si le cluster Kubernetes est d√©ploy√© sur un fournisseur cloud (comme AWS, GCP ou Azure), le type LoadBalancer cr√©e automatiquement un √©quilibreur de charge natif du cloud, offrant des fonctionnalit√©s avanc√©es comme le routage bas√© sur les r√©gions ou la gestion SSL.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: app2
spec:
  selector:
    app: app2
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 9000
      targetPort: 9000
```

Ingress pour app3 (app3-ingress.yaml):
Ce manifeste cr√©e un Ingress pour l'application Django (app3) avec un h√¥te et un chemin sp√©cifiques.
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app3-ingress
spec:
  rules:
  - host: app3.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app3
            port:
              number: 9000
```

#### 3.4  Appliquer les manifestes

Pour appliquer les manifestes de d√©ploiement et de service, utilisez la commande suivante:

```bash
kubectl apply -f ./k8s/
```

La sortie de la commande `kubectl get all` vous montrera les pods, les services et les d√©ploiements cr√©√©s.

```bash
kubectl get all
NAME                        READY   STATUS    RESTARTS   AGE
pod/app1-559d57b7c4-ssd26   1/1     Running   0          118s
pod/app2-768c6d58db-6kqmf   1/1     Running   0          118s
pod/app3-6bf87d8fd5-7rxmq   1/1     Running   0          118s

NAME                 TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
service/app1         NodePort       10.107.62.76     <none>        80:30001/TCP     118s
service/app2         LoadBalancer   10.102.213.245   <pending>     8080:32305/TCP   118s
service/app3         LoadBalancer   10.107.10.161    <pending>     9000:30254/TCP   118s
service/kubernetes   ClusterIP      10.96.0.1        <none>        443/TCP          2m32s

NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app1   1/1     1            1           118s
deployment.apps/app2   1/1     1            1           118s
deployment.apps/app3   1/1     1            1           118s

NAME                              DESIRED   CURRENT   READY   AGE
replicaset.apps/app1-559d57b7c4   1         1         1       118s
replicaset.apps/app2-768c6d58db   1         1         1       118s
replicaset.apps/app3-6bf87d8fd5   1         1         1       118s
```

### 4. Acc√®s externe aux applications

Plusieurs services ont √©t√© utilis√©s pour exposer les applications:
- **NodePort** pour app1 (port 30001)
- **LoadBalancer** pour app2 (port 8080) et app3 (port 9000)

Le NodePort permet d'acc√©der √† l'application via l'adresse IP du n≈ìud et le port sp√©cifi√© (30001 dans ce cas).

Le LoadBalancer permet d'acc√©der √† l'application via une adresse IP externe, mais cela d√©pend de la configuration de votre environnement Kubernetes (par exemple, si vous utilisez un fournisseur de cloud qui prend en charge les LoadBalancers).

Le Port Forwarding dans Kubernetes est une fonctionnalit√© qui permet de rediriger un port  localhost vers un pod dans le cluster Kubernetes. 

#### Commandes pour le port forwarding

Pour acc√©der √† chaque application via le port forwarding, ex√©cutez les commandes suivantes:

```bash
kubectl port-forward service/app1 8081:80
kubectl port-forward service/app2 8082:8080
kubectl port-forward service/app3 8083:9000
```

Cela redirige les ports locaux 8081, 8082, et 8083 vers les ports des services correspondants dans le cluster Kubernetes.

#### Acc√®s aux applications

Pour acc√©der aux applications d√©ploy√©es dans le cluster Kubernetes, plusieurs m√©thodes sont disponibles. Voici les d√©tails pour chaque application et les √©tapes n√©cessaires pour les tester en local.

---

### **App1 (Django)**

- **URL d'acc√®s** : [http://localhost:30001](http://localhost:30001)
- **Port expos√©** : `30001`
- **Type de service** : `NodePort`

#### Commande pour acc√©der √† App1 :
Pour rediriger le port local vers le service Kubernetes correspondant, ex√©cutez la commande suivante :

```bash
kubectl port-forward service/app1 30001:80
```

Cela redirige le port `80` du service Kubernetes vers le port `30001` de votre machine locale. Vous pouvez ensuite acc√©der √† l'application Django via l'URL suivante :

```
http://localhost:30001
```

---

### **App2 (Flask)**

- **URL d'acc√®s** : [http://localhost:8080](http://localhost:8080)
- **Port expos√©** : `8080`
- **Type de service** : `LoadBalancer`

#### Commande pour acc√©der √† App2 :
Pour rediriger le port local vers le service Kubernetes correspondant, ex√©cutez la commande suivante :

```bash
kubectl port-forward service/app2 8080:8080
```

Cela redirige le port `8080` du service Kubernetes vers le port `8080` de votre machine locale. Vous pouvez ensuite acc√©der √† l'application Flask via l'URL suivante :

```
http://localhost:8080
```

---

### **App3 (Django)**

- **URL d'acc√®s** : [http://localhost:9000](http://localhost:9000)
- **Port expos√©** : `9000`
- **Type de service** : `LoadBalancer`

#### Acc√©der √† App3 via Ingress

L'application App3 (Django) est expos√©e √† l'aide d'un objet Kubernetes **Ingress**. Cela permet de g√©rer l'acc√®s externe √† l'application via un nom d'h√¥te et un chemin sp√©cifiques.

##### Configuration Ingress pour App3

Le fichier `app3-ingress.yaml` configure un Ingress pour App3 avec les param√®tres suivants :
- **H√¥te** : `app3.local`
- **Chemin** : `/`
- **Service cible** : `app3`
- **Port cible** : `9000`

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app3-ingress
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app3
            port:
              number: 9000
```

##### √âtapes pour acc√©der √† App3 via Ingress


1. **Acc√©der √† l'application** :
   Une fois le fichier `hosts` configur√© **si n√©c√©ssaire**, ouvrez un navigateur et acc√©dez √† l'URL suivante :
   ```
   http://localhost:80
   ```
   ou si un hostname est configur√© dans le fichier `hosts` (comme `app3.local`), utilisez cette URL :
   ```
    http://app3.local
  ```
  ````

##### V√©rification de l'Ingress

Pour v√©rifier que l'Ingress est correctement configur√© et actif, utilisez la commande suivante :
```bash
kubectl get ingress
```

La sortie devrait ressembler √† ceci :
```bash
NAME            CLASS    HOSTS        ADDRESS        PORTS   AGE
app3-ingress    <none>   app3.local   192.168.49.2   80      5m
```

##### R√©sum√©

Gr√¢ce √† l'Ingress, App3 est accessible via le nom d'h√¥te `app3.local` sur le port 80, simplifiant l'acc√®s et permettant une gestion centralis√©e des r√®gles de routage HTTP/HTTPS.


---

### **Acc√®s simultan√© aux applications**

Pour acc√©der aux trois applications en m√™me temps, vous pouvez ex√©cuter les commandes de redirection de port en arri√®re-plan en ajoutant `&` √† la fin de chaque commande :

```bash
kubectl port-forward service/app1 30001:80 &
kubectl port-forward service/app2 8080:8080 &
```

Cela permet de rediriger les ports pour toutes les applications simultan√©ment. Vous pouvez ensuite acc√©der aux applications via les URL suivantes :

- **App1 (Django)** : [http://localhost:30001](http://localhost:30001)
- **App2 (Flask)** : [http://localhost:8080](http://localhost:8080)
- **App3 (Django)** : [http://localhost:9000](http://localhost)

---

### **V√©rification des services Kubernetes**

Pour v√©rifier que les services sont correctement configur√©s et en cours d'ex√©cution, utilisez la commande suivante :

```bash
kubectl get services
```

La sortie devrait ressembler √† ceci :

```bash
NAME         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
app1         NodePort       10.107.62.76     <none>        80:30001/TCP     5m
app2         LoadBalancer   10.102.213.245   <pending>     8080:32305/TCP   5m
app3         LoadBalancer   10.107.10.161    <pending>     9000:30254/TCP   5m
kubernetes   ClusterIP      10.96.0.1        <none>        443/TCP          10m
```

---

### **Acc√®s via l'IP de Minikube**

Si vous utilisez Minikube, vous pouvez √©galement acc√©der aux applications via l'IP du cluster Minikube. Pour obtenir cette IP, ex√©cutez la commande suivante :

```bash
minikube ip
```

La sortie sera une adresse IP, par exemple :

```
192.168.49.2
```

Vous pouvez ensuite acc√©der aux applications en utilisant cette IP et les ports expos√©s :

- **App1 (Django)** : `http://192.168.49.2:30001`
- **App2 (Flask)** : `http://192.168.49.2:8080`
- **App3 (Django)** : `http://192.168.49.2:9000`

---

### **Suppression des redirections de port**

Pour arr√™ter les redirections de port en arri√®re-plan, utilisez la commande suivante pour lister les processus en cours :

```bash
ps aux | grep kubectl
```

Identifiez les processus li√©s √† `kubectl port-forward` et terminez-les en utilisant leur PID avec la commande `kill` :

```bash
kill <PID>
```

---

En suivant ces √©tapes, vous pouvez facilement acc√©der et tester vos applications d√©ploy√©es dans le cluster Kubernetes, que ce soit via les redirections de port ou l'IP de Minikube.

### 5. Applications

- App1 (Django) ![alt text](image.png)
- App2 (Flask) ![alt text](image-1.png)
- App3 (Django) ![alt text](image-2.png)

### 6. Architecture

![alt text](image-3.png)